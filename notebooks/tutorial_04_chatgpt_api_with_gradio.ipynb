{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOD2uiKlGOT7O2G2U9YBYvz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LLMsLab/chat-gpt-api-lab/blob/exploration%2Fchatgpt-api-understanding/tutorial_04_chatgpt_api_with_gradio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build your ChatGPT Clone in Python with OpenAI ChatGPT API and Gradio"
      ],
      "metadata": {
        "id": "zZdp8S2vcreZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Requirements\n",
        "!pip install -qU python-dotenv openai gradio presidio-analyzer presidio-anonymizer\n",
        "!python -m spacy download en_core_web_lg -qU"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tkxotLKc1u5",
        "outputId": "2c2be646-d435-407a-82d6-ae09812920c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-29 01:20:31.100556: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-29 01:20:33.844408: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary modules\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "import openai\n",
        "from presidio_analyzer import AnalyzerEngine\n",
        "from presidio_anonymizer import AnonymizerEngine\n",
        "import gradio as gr\n",
        "from IPython.display import HTML, display"
      ],
      "metadata": {
        "id": "AaFs3LlBkm-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_css():\n",
        "    \"\"\"\n",
        "    Wraps the lines in the notebook's output.\n",
        "    \"\"\"\n",
        "    display(HTML('''\n",
        "    <style>\n",
        "      pre {\n",
        "        white-space: pre-wrap;\n",
        "      }\n",
        "    </style>\n",
        "    '''))\n",
        "\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ],
      "metadata": {
        "id": "KcqS1K44ktqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive and ensure Google CoLab is running the correct\n",
        "# version of TensorFlow\n",
        "try:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive', force_remount=True)\n",
        "  COLAB = True\n",
        "  print(\"Note: using Google Colab\")\n",
        "  %tensorflow_version 2.x\n",
        "except:\n",
        "  print(\"Note: not using Google Colab\")\n",
        "  COLAB = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "lE6a_7kFkwFY",
        "outputId": "13c91f12-afe2-48ee-8032-685670f7d485"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "      pre {\n",
              "        white-space: pre-wrap;\n",
              "      }\n",
              "    </style>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Note: using Google Colab\n",
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the environment variables from the .env file\n",
        "load_dotenv('/content/drive/MyDrive/Projects/.env')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "qBisNUbRkyl5",
        "outputId": "9ff9f9d0-e266-4ea6-8435-fd7192734869"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "      pre {\n",
              "        white-space: pre-wrap;\n",
              "      }\n",
              "    </style>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieving API keys from the environment\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "cu5CPaFUk7Ib",
        "outputId": "c0fa09c7-cc09-47c5-87bc-dfb3214035b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "      pre {\n",
              "        white-space: pre-wrap;\n",
              "      }\n",
              "    </style>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_and_anonymize(text: str):\n",
        "    \"\"\"\n",
        "    Analyze and anonymize PII data from a given text string.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    text : str\n",
        "        The text to be analyzed and anonymized.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    str\n",
        "        The anonymized text.\n",
        "\n",
        "    Example\n",
        "    -------\n",
        "    >>> text = \"Mr. Smith's phone number is 212-555-5555, his SSN is \\\n",
        "    >>> 432-56-5654, and his credit card number is 344078656339539\"\n",
        "    >>> print(analyze_and_anonymize(text))\n",
        "    \"\"\"\n",
        "    # Set up the engine, loads the NLP module (spaCy model by default)\n",
        "    # and other PII recognizers\n",
        "    analyzer = AnalyzerEngine()\n",
        "\n",
        "    # Define the entities to analyze\n",
        "    entities = [\n",
        "        \"CREDIT_CARD\",\n",
        "        \"CRYPTO\",\n",
        "        \"DATE_TIME\",\n",
        "        \"EMAIL_ADDRESS\",\n",
        "        \"IBAN_CODE\",\n",
        "        \"IP_ADDRESS\",\n",
        "        \"NRP\",\n",
        "        \"LOCATION\",\n",
        "        \"PERSON\",\n",
        "        \"PHONE_NUMBER\",\n",
        "        \"MEDICAL_LICENSE\",\n",
        "        \"URL\",\n",
        "        \"US_BANK_NUMBER\",\n",
        "        \"US_DRIVER_LICENSE\",\n",
        "        \"US_ITIN\",\n",
        "        \"US_PASSPORT\",\n",
        "        \"US_SSN\",\n",
        "    ]\n",
        "\n",
        "    # Call analyzer to get results\n",
        "    results = analyzer.analyze(text=text, entities=entities, language=\"en\")\n",
        "\n",
        "    # Analyzer results are passed to the AnonymizerEngine for anonymization\n",
        "    anonymizer = AnonymizerEngine()\n",
        "\n",
        "    # Anonymize the text\n",
        "    anonymized_text = anonymizer.anonymize(text=text, analyzer_results=results)\n",
        "\n",
        "    return anonymized_text.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "3g67XGb8o_Ag",
        "outputId": "6e8bd7c3-62f8-4c14-b1c3-078aa27ff8f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "      pre {\n",
              "        white-space: pre-wrap;\n",
              "      }\n",
              "    </style>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "message_history = [{\"role\": \"user\", \"content\": f\"You are an assistant.\"},\n",
        "                   {\"role\": \"assistant\", \"content\": f\"OK\"}]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "wLwzK8wws8qE",
        "outputId": "7a293aa3-f261-4504-9aba-6c136e8b9400"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "      pre {\n",
              "        white-space: pre-wrap;\n",
              "      }\n",
              "    </style>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clear_history():\n",
        "    global message_history\n",
        "    message_history = [{\"role\": \"user\", \"content\": f\"You are an assistant.\"},\n",
        "                   {\"role\": \"assistant\", \"content\": f\"OK\"}]\n",
        "\n",
        "message_history = [{\"role\": \"user\", \"content\": f\"You are an assistant.\"},\n",
        "                   {\"role\": \"assistant\", \"content\": f\"OK\"}]\n",
        "\n",
        "def predict(input):\n",
        "    \"\"\"\n",
        "    Given a user's input, this function predicts a response by sending the\n",
        "    anonymized input to the OpenAI API. This prediction is then appended to the\n",
        "    message history. Finally, the function returns a list of pairs of\n",
        "    consecutive messages from the history, skipping the pre-prompt.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    input : str\n",
        "        User's original input message\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    list\n",
        "        A list of tuples. Each tuple contains a pair of consecutive messages \n",
        "        from the message history.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Anonymize message\n",
        "    input_anonymized = analyze_and_anonymize(input)\n",
        "\n",
        "    # Tokenize the new input sentence\n",
        "    message_history.append(\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": (\n",
        "                #f\"**User's original input:**\\n {input}\\n\"\n",
        "                f\"**Anonymized version prepared for the \" \n",
        "                f\"OpenAPI request:**\\n {input_anonymized}\"\n",
        "            ),\n",
        "        }\n",
        "    )\n",
        "\n",
        "    completion = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\", messages=message_history\n",
        "    )\n",
        "    \n",
        "    # Just the reply text\n",
        "    reply_content = completion.choices[0].message.content\n",
        "\n",
        "    message_history.append({\"role\": \"assistant\", \"content\": f\"{reply_content}\"})\n",
        "\n",
        "    # Get pairs of msg[\"content\"] from message history, skipping the pre-prompt:\n",
        "    response = [\n",
        "        (message_history[i][\"content\"], message_history[i + 1][\"content\"])\n",
        "        for i in range(2, len(message_history) - 1, 2)\n",
        "    ]  # Convert to tuples of list\n",
        "\n",
        "    return response\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "UO7Xg6S6ra4A",
        "outputId": "04437dc8-51f9-439d-b87e-296b2f4b06e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "      pre {\n",
              "        white-space: pre-wrap;\n",
              "      }\n",
              "    </style>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks(theme=\"darkhuggingface\") as demo:\n",
        "    chatbot = gr.Chatbot()\n",
        "\n",
        "    with gr.Row():\n",
        "        txt = gr.Textbox(\n",
        "            show_label=False, placeholder=\"Enter text and press enter\"\n",
        "        ).style(container=False)\n",
        "    \n",
        "    clear = gr.Button(\"New chat\")\n",
        "    txt.submit(predict, txt, chatbot)\n",
        "    txt.submit(None, None, txt, _js=\"() => {''}\")\n",
        "    clear.click(clear_history, None, chatbot, queue=False)\n",
        "\n",
        "#demo.launch(share=True, auth=(\"Stellar\",\"AmAriLLo901\"), auth_message=\"Check your Login details sent to your email\")\n",
        "demo.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "zpPd2UaFqgKG",
        "outputId": "d8e55784-305f-4650-9a49-ca5d2123af07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "      pre {\n",
              "        white-space: pre-wrap;\n",
              "      }\n",
              "    </style>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gradio/blocks.py:666: UserWarning: Cannot load darkhuggingface. Caught Exception: The space darkhuggingface does not exist\n",
            "  warnings.warn(f\"Cannot load {theme}. Caught Exception: {str(e)}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://6ef9981e55d482351e.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://6ef9981e55d482351e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y0dgH1VVBgGF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}